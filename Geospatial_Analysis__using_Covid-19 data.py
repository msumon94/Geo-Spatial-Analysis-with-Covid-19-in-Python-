# -*- coding: utf-8 -*-
"""Udemy_Geospatial Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12s3roBXJyr78jY-vg5hn9UeFpEiTycjx
"""

import pandas as pd 
import numpy as np
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv('zomato.csv')

df.isna().sum()

df.dropna(axis='index', subset=['location'], inplace=True )
df.isna().sum() #look now all missing values for column "location" are deleted

print(df['location'].unique())

print(len(df['location'].unique()))

print(len(df['name'].unique()))
print(df['name'].head())

locations=pd.DataFrame()
print(locations)  ##SO, it is new blank dataframe

locations['Name']=df['name'].unique()  #I am just adding a new column to dataframe. The column is exactly same as "name"
print(locations.head())

!pip install geopy

from geopy.geocoders import Nominatim

geolocator=Nominatim(user_agent='app', timeout=None)

lat=[]  #a list for latitude
lon=[]  #a list for longitude 

for location in locations['Name']:
    location=geolocator.geocode(location)
    if location is None:
        lat.append(np.nan)
        lon.append(np.nan)
    else:
        lat.append(location.latitude)
        lon.append(location.longitude)

print(lat, lon)

print(locations.head())  #locations is a list.

locations['latitude']=lat   #adding new column to the list
locations['longitude']=lon  #adding another new column

print(locations.head())  #again see the difference.

#converting this locations to a csv file

locations.to_csv(r'C:\Users\s885m749\Downloads\Python__Udemy/zomato_locations.csv', index=False)

df['location'].value_counts()  #return the the total number of each location. So we can know the restaurent number at each location.

Rest_locations= df['location'].value_counts().reset_index()  #converted into a dataframe
Rest_locations

Rest_locations.columns=["Name",  "Count"]  #changing the columns name of datafram
print(Rest_locations)

Restaurant_locations=Rest_locations.merge(locations, on='Name', how='left')  #we can also drop missing values by dropna()
print(Restaurant_locations.head())

Restaurant_locations.isna().sum()  #there are missing values for latitude and longitude

!pip install folium

def generatebasemap(default_location=[12.96697, 77.58728], default_zoom_start=12 ):
    basemap=folium.Map(location=default_location, zoom_start=default_zoom_start)
    return basemap

import folium
basemap=generatebasemap()
print(basemap)  #this will not show the map
basemap  #map will be shown now)

from folium.plugins import HeatMap

Restaurant_locations[['Count', 'latitude',   'longitude']] #two throd brackets because we are calling three columns from four columns.

Restaurant_locations=Restaurant_locations.dropna() #error will show with NaN values. So drop the values with NaN
print(Restaurant_locations) #No NaN Values
HeatMap(Restaurant_locations[['Count', 'latitude',   'longitude']]).add_to(basemap)  #it won't work for missing values

basemap

from folium.plugins import FastMarkerCluster  #it will make change for zoom out and zoomin

FastMarkerCluster(Restaurant_locations[['Count', 'latitude',   'longitude']]).add_to(basemap)  #there will be a change for zoom out and zoom in

basemap

df.head()  #see the rate column

print(df['rate'].unique())  #there is NaN values. drop this
df.isna().sum()

df.dropna(axis=0, subset=['rate'], inplace=True)  #drop all NaN values in 'rate' column

def split(x):
    return x.split('/')[0]  #split values based on '/ and get the first (0 index) value

df['rating']= df['rate'].apply(split)  # a new column named 'rating' is added. rating's values are from splitted value of rate
df.head()

df['rating'].unique()  #still New as a rating

df.replace("New", 0, inplace=True)

df.replace("-", 0, inplace=True)

df.replace("NEW", 0, inplace=True)

df['rating'].unique()   #no missing and no string values

df.groupby('location')['rating'].mean()  #this wont work because non-numeric values

df.dtypes  #rating column is an object. We need to convert it to numeric values.

df['rating']=pd.to_numeric(df['rating'])  #convert object to numeric

df['rat']=pd.to_numeric(df['rating'])  #'rating' column is converted to numeric values and added as 'rat'

df.head()  #a new column named 'rat' is added same as 'rating' column

del df['rat']  #deleting a column rat

df.groupby('location')['rating'].mean()   #average of ratng for each location

df.groupby('location')['rating'].mean().sort_values(ascending=False) #from larger to smaller

avg_rating=df.groupby('location')['rating'].mean().sort_values(ascending=False).values  #average values as array
print(avg_rating)

new_location=df.groupby('location')['rating'].mean().sort_values(ascending=False).index
print(location)

rating=pd.DataFrame()  #blank dataframe
print(rating)

lat=[]  #a list for latitude
lon=[]  #a list for longitude 

for loc in new_location:
    loc=geolocator.geocode(loc)
    if loc is None:
        lat.append(np.nan)
        lon.append(np.nan)
    else:
        lat.append(loc.latitude)
        lon.append(loc.longitude)

lat

rating['location']=new_location  #adding a new column named 'location' same as 'location'
rating['latitude']=lat
rating['longitude']=lon
rating['avg_rating']=avg_rating
print(rating)

print(rating.head())

rating.isna().sum()  #if there is any missing values

rating.dropna(inplace=True)

rating.isna().sum()

rating[['latitude', 'longitude', 'avg_rating']]  #dataframe

HeatMap(rating[['latitude', 'longitude', 'avg_rating']]).add_to(basemap) 
basemap

df.head()

filter=df['cuisines']=="North Indian"  #this will filter the dataframe. cuisines are North Indian
df2=df[filter]
df2

df.groupby('location')['url'].count() #for each location we have different 'url'

df2.groupby('location')['url'].count()

north_india=df2.groupby('location')['url'].count().reset_index()
print(north_india)

north_india=north_india.rename(columns={'location':'Name', 'url':'count'}) #renaming the column names of  dataframe 'north_india'
print(north_india)

print(locations)  #Both 'locations' and 'north_india' have "Name" column
north_india=north_india.merge(locations, on='Name', how='left').dropna()   #for merging column "Name" should be same
print(north_india)

north_india[['latitude', 'longitude', 'count']] #pass this to heatmap

HeatMap(north_india[['latitude', 'longitude', 'count']], zoom=20, radius=15).add_to(basemap)  
basemap  ##north indian restaurant in Bengalore

#so I can automate the Heatmap filtering. 

def Heatmap_zone(zone):
    filter=df['cuisines']==zone  #this will filter the dataframe. cuisines are North Indian
    df2=df[filter]
    
    df_zone=df2.groupby('location')['url'].count().reset_index()
    df_zone=df_zone.rename(columns={'location':'Name', 'url':'count'}) #renaming the column names of  dataframe 'north_india'
    
    df_zone=df_zone.merge(locations, on='Name', how='left').dropna() 
    
    HeatMap(df_zone[['latitude', 'longitude', 'count']], zoom=20, radius=15).add_to(basemap)  
    
    return basemap

Heatmap_zone('South Indian')

"""# Analyzing average temparature of country"""

import pandas as pd
import numpy as np
import seaborn as sns
import plotly.express as px
from plotly.offline import init_notebook_mode
init_notebook_mode(connected= True)

global_temp_country=pd.read_csv('GlobalLandTemperaturesByCountry.csv')
global_temp_country.head()

global_temp_country.shape  #lets see the shape/size of the file

global_temp_country.isna().sum() #check missing values

global_temp_country.dropna(axis='index', how='any', subset=['AverageTemperature'], inplace=True) #remove missing values for 'AverageTemperature' column

global_temp_country.isna().sum()  #now chekc is there any missing values

print(global_temp_country['Country'].nunique()) #print total unique values of country
global_temp_country['Country'].unique()  #this will print unique country list.

dict={
    'Denmark (Europe)':'Denmark',
    'France (Europe)': 'France',
    'Netherlands (Europe)': 'Netherlands',
    'United Kingdom (Europe)': 'United Kingdom',
    'Congo (Democratic Republic Of The)':'Congo',
    
}

global_temp_country['Country'].replace(dict, inplace=True)

global_temp_country.groupby(['Country'])['AverageTemperature'].mean()

avg_temp=global_temp_country.groupby(['Country'])['AverageTemperature'].mean().to_frame()  #converting it into dataframe
print(avg_temp)

avg_temp=avg_temp.reset_index()  #
print(avg_temp)

fig=px.choropleth(avg_temp, locations='Country', locationmode='country names', color='AverageTemperature' )
fig  #print fig will not work

fig.update_layout(title='choropleth map of avg temp')

"""#now new task started. we will be using global temperature now 
#HERE IS THE BREAK from previous one
"""

global_temp=pd.read_csv('GlobalTemperatures.csv')
global_temp.head()

print(global_temp['dt'])  #year
print('......', '//Break//', '..........')
print(global_temp['dt'][0])  #year of first row. finally we will use all row
print(global_temp['dt'][0].split('-'))  #look, how year is splitted and a list is made
global_temp['dt'][0].split('-')[0]  #getting the first index value of year list. but we get for first row.

def fetch_year(date):
    return date.split('-')[0]   #later on, we will apply this function

global_temp['dt'].apply(fetch_year)  #we will store this in a new column

global_temp['years']=global_temp['dt'].apply(fetch_year)  #adding a new column
global_temp.head()

global_temp.isna().sum() #there are missing values

#we dont need it
adf2= pd.DataFrame() #creating a blank dataframe
adf2['years']=global_temp['years']  #adding a new column
adf2['temp']=global_temp['LandAverageTemperature']  #adding another column
print(adf2.sort_values(by='temp'))  #now sorting it by 'temp'

adf2.sort_values(by='temp').reset_index()  #looks how indexing changed due to sorting

global_temp.groupby('years').agg({'LandAverageTemperature':'mean', 'LandMinTemperatureUncertainty':'mean'})

data=global_temp.groupby('years').agg({'LandAverageTemperature':'mean', 'LandMinTemperatureUncertainty':'mean'}).reset_index()
data.head()

#adding two new column
data['Uncertainty Top']=data['LandAverageTemperature'] + data['LandMinTemperatureUncertainty']
data['Uncertainty Bottom']=data['LandAverageTemperature'] - data['LandMinTemperatureUncertainty']

data.head()

print(data.isna().sum())

#delet missing values
data.dropna(axis='index', how='any', subset=['LandMinTemperatureUncertainty'], inplace=True)

data.isna().sum()  #check if there is missing values

print(data.columns)  #copy paste column name from hear



fig=px.line(data, x='years', y=['LandAverageTemperature','Uncertainty Top', 'Uncertainty Bottom'], title='Average Land temp in World')
fig

"""###  ................................. .........................
#Visualize average temperature in each season
.............................................
"""

global_temp.head()

global_temp['dt'].dtype  #see dtype('0') means string.

global_temp['dt']=pd.to_datetime(global_temp['dt'])

global_temp['dt'].dtype

#this is for test. we dont need days
global_temp['days']=global_temp['dt'].dt.day  #so by this, I can also add year. Previously different method was used to add year
global_temp.head()

global_temp.drop('days', axis=1, inplace=True)  #dropping a days column. 
global_temp.head()

global_temp['month']=global_temp['dt'].dt.month
global_temp.head()

def get_season(month):
    if month>=3 and month<=5:
        return 'Spring'
    elif month>=6 and month<=8:
        return 'Summer'
    elif month>=9 and month<=11:
        return 'autumn'
    else:
        return 'winter'

global_temp['season']=global_temp['month'].apply(get_season)  #adding season column 
global_temp #see the season column

print(global_temp['years'].nunique())  #number of unique years
global_temp['years'].unique()

years=global_temp['years'].unique()

print('shape of global_temp=', global_temp.shape)

for year in years:
    current_df=global_temp[global_temp['years']==year]  #this is filtering. 
    

print('shape of current_df=', current_df.shape) #see the difference of size of global_temp and current_df
current_df

#create empty list of seasons
spring_temps=[] 
summer_temps=[]
autumn_temps=[]
winter_temps=[]

#for checking.
check=pd.DataFrame()
for year in years:
    current_df=global_temp[global_temp['years']==year]  #this is filtering. 
    x=current_df[current_df['season']=='Spring']['LandAverageTemperature']  #this is printing 'LandAverageTemperature' for each month of season 'Spring'
    y=current_df[current_df['season']=='Spring']['LandAverageTemperature'].mean() #This will print mean of 'LandAverageTemperature' when 'season'=='Spring'
    check['y']=y
print(x)  
print(check.shape)

for year in years:
    current_df=global_temp[global_temp['years']==year]  #this is filtering. 
    current_df[current_df['season']=='Spring']['LandAverageTemperature'].mean()  #again filtering 
    spring_temps.append(current_df[current_df['season']=='Spring']['LandAverageTemperature'].mean())
    summer_temps.append(current_df[current_df['season']=='Summer']['LandAverageTemperature'].mean())
    autumn_temps.append(current_df[current_df['season']=='autumn']['LandAverageTemperature'].mean())
    winter_temps.append(current_df[current_df['season']=='winter']['LandAverageTemperature'].mean())

spring_temps  #it should have 266 values. it is showing 'LandAverageTemperature' for each unique year for 'Spring'

#opening an empty dataframe and adding values
season=pd.DataFrame()

season['year']=years  #years is defined earlier
season['spring_temps']=spring_temps
season['summer_temps']=summer_temps
season['autumn_temps']=autumn_temps
season['winter_temps']=winter_temps

print(season.shape)   #season' dataframe has 266 rows. this is same as unique number of years from 'global_temp'
season.head()

season.columns  #copy paste column names from here

fig=px.line(season, x='year', y=['spring_temps', 'summer_temps', 'autumn_temps', 'winter_temps'], title='Avg Temp in Each season')
fig  #print(fig) will not work

"""##.............................

Analyze trend in temperature for the top Economies

###..........................
"""

continent=['Russia', 'United States', 'China', 'Japan', 'Australia', 'India' ]  #because these continent are present in global_temp_country['Country']

# global_temp_country=pd.read_csv('GlobalLandTemperaturesByCountry.csv')

print(global_temp_country.shape)  #544,811 rows/observations/data
print(global_temp_country['Country'].nunique())  #237 unique countries
global_temp_country

#for checking
m=pd.DataFrame()
m['X']=global_temp_country['Country'].isin(continent)
print(m)

n=pd.DataFrame()

q=pd.DataFrame()
    
for i in m:
    if i=='True':        
        n['i']=i
    else:
        q['i']=i
        #print(q)
      
        
#print(n)     
print(q)

#for checking 
new_continent=['Åland','Russia', 'United States', 'China', 'Japan', 'Australia', 'India' ]  #we added a new country name. 

global_temp_country['Country'].isin(new_continent)  #True values are shown because country "Aland" is in "new_continent" dataframe

global_temp_country['Country'].isin(continent)  #"False values are shown because country "Aland" is not in "coninent" dataframe

#this is a filtering. only if 'country' name is present in "continent" then, the values are returned.

continent_df=global_temp_country[global_temp_country['Country'].isin(continent)]

print(continent_df.shape)      #see the rows are 13598. That means after filtering rows are reduced from 544,811 to 13,598
print(global_temp_country.shape)  #here rows are 544,811. 

continent_df

continent_df['years']=continent_df['dt'].apply(fetch_year)  #fetch_year is a function defined earlier
continent_df

continent_df.groupby(['years', 'Country']).agg({'AverageTemperature':'mean'})

#we will perform analysis on this avg_temp

avg_temp=continent_df.groupby(['years', 'Country']).agg({'AverageTemperature':'mean'}).reset_index()
avg_temp

fig=px.line(avg_temp, x='years', y='AverageTemperature', color='Country', title='Avg land temp in world')
fig    #also fig.show() works to view the figure

""".........................
Analysis of average temperature of usa states
'''''''''''''''''''''''''''''
"""

global_temp_state=pd.read_csv('GlobalLandTemperaturesByState.csv')
global_temp_state

filter=global_temp_state['Country']=='United States'
USA=global_temp_state[filter]
USA

USA.isna().sum() #missing value

USA.dropna(inplace=True) #delete missing value

USA.isna().sum()  #no missing valaues

print(USA["State"].nunique())
USA["State"].unique()

state={'Georgia (State)':'Georgia', 'District Of Columbia':'Columbia' }

USA['State'].replace(state, inplace=True)

USA=USA[['AverageTemperature', 'State']]
USA  #previously, it has five columns

USA_temp=USA.groupby('State')['AverageTemperature'].mean().reset_index()  #we will have 51 rows now. Because groupbby 'state'
USA_temp

!pip install opencage

from opencage.geocoder import OpenCageGeocode

key='3b296e98bb0041eda013cb20f85188d2'

geocoder=OpenCageGeocode(key)

location='Sunamganj, Bangladesh'
results=geocoder.geocode(location)  #this will give geometry [latitude, longitude] 
results

results[0]['geometry']['lat']  #from results we are getting latitude

results[0]['geometry']['lng']

#similarly, we will access to latitude and longitude of US states

list_lat=[]
list_long=[]

for state in USA_temp['State']:
    results=geocoder.geocode(state)
    lat=results[0]['geometry']['lat']
    long=results[0]['geometry']['lng'] 
    
    list_lat.append(lat)
    list_long.append(long)

print(list_lat)
print('.................break..................................................................................')
print(list_long)

#adding latitude and longitude in USA_temp

USA_temp['latitude']=list_lat
USA_temp['longitude']=list_long

USA_temp.head()

import folium 
from folium.plugins import HeatMap

basemap=folium.Map()
basemap

USA_temp.columns

USA_temp[['latitude', 'longitude', 'AverageTemperature' ]]

HeatMap(USA_temp[['AverageTemperature', 'latitude', 'longitude']]).add_to(basemap)
basemap

"""##

visualize average temperature for Indian Cities by month

##
"""

cities=pd.read_csv('GlobalLandTemperaturesByCity.csv')
cities

India=cities[cities['Country']=='India'] #filtering
India.shape

India.head()

print(India['City'].nunique())

India['City'].unique()

cities=['New Delhi', ' Bangalore', 'Hyderabad', 'Pune', 'Madras', 'Gurgaon']

India['City'].isin(cities)

cities=India[India['City'].isin(cities)]  #again filtering
print(cities.shape)  #after filtering, only 13,065 rows
cities.head()

#we need to delete extra E and N after latitude and longitude
cities['Latitude']=cities['Latitude'].str.strip('N')
cities['Longitude']=cities['Longitude'].str.strip('E')

cities.head()

#we don't have month  column. But we need month. Fetch month from date

cities['dt'].dtype  #look the data type of cities['dt']. Need to convert it

cities['dt']=pd.to_datetime(cities['dt'])  #cities['dt'] is converted to datetime

cities['dt'].dtype

cities['dt'].dt.month  #dt.month itself is a function

#adding month column
cities['Month']=cities['dt'].dt.month  
print(cities.shape)  #still rows number are same. That means no further filtering was used
cities.head()

cities['City'].nunique() #5 cities only. because we used 5 cities earlier.

#we will get mean temperature for each cities for each month. 
cities_temp=cities.groupby(['Month', 'City'])['AverageTemperature'].mean().to_frame().reset_index()
cities_temp

cities_temp.columns

#renaming the column name. Only change is 'Mean_temp'
cities_temp.columns=['month', 'City', 'Mean_temp']
print(cities_temp.head())
cities_temp.shape

df=cities_temp.merge(cities, on='City')
print(df.shape)  #156,780 rows. But 'cities' has 13065 rows and 'cities_temp' has 60 rows. 
df.head()

data=df.drop_duplicates(subset=['month', 'City'])
print(data.shape)
data.head()

data.columns

data2=data[['month', 'City', 'Mean_temp', 'Country', 'Latitude', 'Longitude']]
data2.head()

data2.columns

import plotly.graph_objs as go

data3=[go.Heatmap(x=data2['month'], y=data2['City'], z=data2['Mean_temp'])]
data3 #its a list

layout=go.Layout(title='Avg Temp of major cities by month')

go.Figure(data=data3, layout=layout)

import folium 
from folium.plugins import HeatMap
basemap=folium.Map() 
basemap

print(data2.columns)
print(data2.shape)  #60 rows
data2.head()

#for checking 
for id, row in data2.iterrows():
    print(id)  #gives the index values
    print(row) #return the each row

for id, row in data2.iterrows():
    folium.Marker(location=[row['Latitude'], row['Longitude']], popup=row['Mean_temp']).add_to(basemap)  #without popup paramter no values of Mean_temp are shown
basemap    

#notice that basemap is showing 5 places only. But in our data2 we have 60 rows ( 5 place * 12 months).  Here folium.marker() makes a spatial analysis. It average the temperature for different months for each location.

"""# Covid-19 Spatial analysis


"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

!pip install plotly

import plotly.express as px

dir(px)  #all functions of px

import plotly
import plotly.graph_objs as go
from plotly import tools
from plotly.offline import init_notebook_mode, plot, iplot

dir(plotly)

print(plotly.__version__)

#this data is kept updating
current_data=pd.read_csv('https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv')

current_data.head()

current_data.tail(10)

current_data.shape

current_data['Country'].nunique()

fig=px.choropleth(current_data, locations='Country', locationmode='country names', color='Confirmed', animation_frame='Date')
fig.show()

fig.update_layout(title='Choropleth map of confirmed cases till today', template='plotly_dark')
fig.show()

#by  continent. change in one paramter, scope='asia'
fig=px.choropleth(current_data, locations='Country', locationmode='country names', color='Confirmed', animation_frame='Date', scope='asia')
fig.update_layout(title='Choropleth map of confirmed cases till today by coninent', template='plotly_dark')
fig.show()

fig=px.scatter_geo(current_data, locations='Country', locationmode='country names', color='Confirmed', size='Confirmed', hover_name='Country', animation_frame='Date', title='Spread over time')
fig.show()

fig.update(layout_coloraxis_showscale=False, layout_template='plotly_dark')

current_data.head()

current_data.columns

fig=px.choropleth(current_data, locations='Country', hover_name='Country', locationmode='country names', color='Recovered', animation_frame='Date', title='Choropleth map of Recovered cases till today')
fig.update_layout(template='plotly_dark')  
fig.show()

fig=px.scatter_geo(current_data, locations='Country', locationmode='country names', color='Recovered', size='Recovered', hover_name='Country', animation_frame='Date', title='Recovered over time')
fig.update(layout_coloraxis_showscale=False, layout_template='plotly_dark')
fig.show()

current_data.head()

fig=px.choropleth(current_data, locations='Country', hover_name='Country', locationmode='country names', color='Deaths', animation_frame='Date', title='Choropleth map of Deaths cases till today')
fig.update_layout(template='plotly_dark')  
fig.show()

fig=px.scatter_geo(current_data, locations='Country', locationmode='country names', color='Deaths', size='Deaths', hover_name='Country', animation_frame='Date', title='Deaths over time')
fig.update(layout_coloraxis_showscale=False, layout_template='plotly_dark')
fig.show()

#to extract latitude and longtitude
!pip install geopy

import geopy
from geopy.geocoders import Nominatim

geolocator=Nominatim(user_agent='app')

#Extracting latitude and longitude
location=geolocator.geocode('Eiffel Tower')
print(location.latitude, location.longitude)

#Extracting latitude and longitude
location=geolocator.geocode('Sylhet')
print(location.latitude, location.longitude)  #it will take few seconds

#dataframe
df=current_data
df

#dataframe
df=current_data.copy()
df.head(20)  #first 20 rows

df=df[df['Country']=='Afghanistan']  #filtering for specific country
df

df.groupby(['Country'])[['Confirmed', 'Recovered', 'Deaths']].max()  #previously we did for mean() values.

current_data.groupby(['Country'])[['Confirmed', 'Recovered', 'Deaths']].max()

df2=current_data.groupby(['Country'])[['Confirmed', 'Recovered', 'Deaths']].max().reset_index()
df2

#to visualize, we need latitude and longitude
lat=[]
lon=[]
geolocator=Nominatim(user_agent='app')
for location in df2['Country']:
    location=geolocator.geocode(location)
    if location is None:
        lat.append(np.nan)
        lon.append(np.nan)
    else:
        
        lat.append(location.latitude)
        lon.append(location.longitude)

#check
lat

df2

df2['latitude']=lat  # adding latitude
df2['longitude']=lon  # longtiude to df2 as new column
df2     #geo_loc  column was previously added

"""#type(lat_lon) #lat_lon is a list

#type(df2['geo_loc'][0])  #tuple

#unzip the geo_loc

x=zip(df2['geo_loc'])  #it is working now
x

x, y= zip(df2['geo_loc']) #not working

#zip(*np.array(df2['geo_loc'])) #not working 
x=np.array(df2['geo_loc'])

df2.drop('geo_loc', axis=1, inplace=True)  #dropping column geo_loc
"""

!pip install folium

import folium

folium.Map(location=[54, 15], zoom_start=2)

basemap=folium.Map(location=[54, 15], zoom_start=2)

df2

df2.isna().sum()

df2.dropna()

df2.isna().sum()

df2.dropna(axis=0, subset='latitude', how='any', inplace=True) #inplace=True is required

df2.isna().sum()

df2['Country'].nunique()

"""#wont work if location has NaN values

for id, row in df2.iterrows():
    folium.Marker(location=[row['latitude'], row['longitude']], popup=row['Confirmed']).add_to(basemap)  #without popup paramter no values of Mean_temp are shown
basemap   #it will mark 197 values. Because 197 unique location
"""

folium.Marker(location=[df2['latitude'][0], df2['longitude'][0]], popup=df2['Confirmed'][0]).add_to(basemap) 
basemap  #will mark only one point.

#check
df2['latitude'][0] #first row of column latitude

#wont work if location has NaN values

for id, row in df2.iterrows():
    folium.Marker(location=[row['latitude'], row['longitude']], popup=row['Confirmed'], tooltip=row['Country']).add_to(basemap)  #without popup paramter no values of Mean_temp are shown
basemap   #it will mark 197 values. Because 197 unique location

df2.columns

basemap_2=folium.Map(location=[24,91], zoom_start=2)  #map position will be changed based on location

#wont work if location has NaN values

for id, row in df2.iterrows():
    folium.Marker(location=[row['latitude'], row['longitude']], popup=row['Recovered'], tooltip=row['Country']).add_to(basemap_2)  #without popup paramter no values of Mean_temp are shown
basemap_2   #it will mark 197 values. Because 197 unique location

basemap_3=folium.Map(location=[24,91], zoom_start=2)  #map position will be changed based on location

#wont work if location has NaN values

for id, row in df2.iterrows():
    folium.Marker(location=[row['latitude'], row['longitude']], popup=row['Recovered'], tooltip=row['Country'], draggable=True).add_to(basemap_3)  #without popup paramter no values of Mean_temp are shown
basemap_3   #it will mark 197 values. Because 197 unique location

"""###...............

Advanced Geospatial Analysis

##..........
"""

from folium.plugins import MarkerCluster

basemap_4=folium.Map(location=[24,91], zoom_start=2)  #map position will be changed based on location

mc=MarkerCluster()
#wont work if location has NaN values

for id, row in df2.iterrows():
    folium.Marker(location=[row['latitude'], row['longitude']], popup=row['Recovered'], tooltip=row['Country']).add_to(mc)  #without popup paramter no values of Mean_temp are shown
    
mc.add_to(basemap_4)  

basemap_4   #it will mark 197 values. Because 197 unique location

#Alternative
basemap_5=folium.Map(location=[24,91], zoom_start=2)  #map position will be changed based on location

mc=MarkerCluster()

#wont work if location has NaN values

for id, row in df2.iterrows():
    mc.add_child(folium.Marker(location=[row['latitude'], row['longitude']], popup=row['Recovered'], tooltip=row['Country']))  #without popup paramter no values of Mean_temp are shown
    
basemap_5.add_child(mc)  

basemap_5

"""#for checking. Cicile can be plotted

folium.Circle()

folium.CircleMarker()

b=folium.Map(location=[24,91], zoom_start=2)
folium.Circle(location=[24, 91], radius=50).add_to(b)
b
"""

#same as previous
basemap_6=folium.Map(location=[24,91], zoom_start=2)  #map position will be changed based on location

mc=MarkerCluster()

#wont work if location has NaN values

for id, row in df2.iterrows():
    mc.add_child(folium.Marker(location=[row['latitude'], row['longitude']], popup=row['Deaths'], tooltip=row['Country']))  #without popup paramter no values of Mean_temp are shown
    
basemap_6.add_child(mc)  

basemap_6

"""###........

New lesson Geographical HeatMap

##..........
"""

from folium.plugins import HeatMap

df2.head()

df2.columns

basemap_7=folium.Map(location=[54,15], title='openstreetmap', zoom_start=2)  #map position will be changed based on location

HeatMap(data=df2[['latitude', 'longitude', 'Confirmed']], radius=20).add_to(basemap_7)
basemap_7

